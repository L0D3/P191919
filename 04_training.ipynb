{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "778860cc",
   "metadata": {},
   "source": [
    "# Model Training\n",
    ">  Includes the training phase of the neural networks for all datasets. In order to run the training we recommend to use the python scripts since it might take ~20 hours.\n",
    "```\n",
    "python training.py --log=(all|binet|pdc20|pdc21)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c290dfa",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#PDC-2020\" data-toc-modified-id=\"PDC-2020-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>PDC 2020</a></span></li><li><span><a href=\"#PDC-2021\" data-toc-modified-id=\"PDC-2021-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>PDC 2021</a></span></li><li><span><a href=\"#Binet-datasets\" data-toc-modified-id=\"Binet-datasets-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Binet datasets</a></span></li><li><span><a href=\"#Shell-Util\" data-toc-modified-id=\"Shell-Util-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Shell Util</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e483b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c38364f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae4fe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "from dapnn.imports import *\n",
    "from dapnn.data_processing import *\n",
    "from dapnn.anomaly import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70890d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb2b1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 04_training.ipynb.\n"
     ]
    }
   ],
   "source": [
    "notebook2script('04_training.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1184afa4",
   "metadata": {},
   "source": [
    "## PDC 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4394a3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def train(fn,log_name,store_path='models',epoch=25,ws=5): \n",
    "    cols= get_attr(attr_dict,fn)\n",
    "    log = import_log(fn,cols)\n",
    "    o,dls,categorify = training_dl(log,cols,ws=ws)\n",
    "    p = f'{store_path}/{log_name}_vocab.p'\n",
    "    with open(p, \"wb\") as output_file:\n",
    "        pickle.dump(categorify, output_file)\n",
    "    \n",
    "    emb_szs = get_emb_sz(o)\n",
    "    m=MultivariateModel(emb_szs)\n",
    "    loss=partial(multi_loss_sum,o)\n",
    "    train_val = train_validate(dls,m,loss=loss,metrics=get_metrics(o),epoch=epoch,show_plot=False,print_output=False,store_path=store_path,model_name=log_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1aad85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def train_pdc20_logs():\n",
    "    store_path='models/pdc2020'\n",
    "    for training_log in progress_bar(glob.glob('data/csv/PDC2020_training/*')):\n",
    "        log_name = training_log.split('.')[0].split('_')[-1]\n",
    "        train(training_log,log_name,store_path=store_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc08cd96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='173' class='' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      90.10% [173/192 23:08<02:32]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "909deeb8",
   "metadata": {},
   "source": [
    "## PDC 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349707fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def train_pdc21_logs():\n",
    "    store_path='models/pdc2021'\n",
    "    for training_log in progress_bar(glob.glob('data/csv/PDC2021_training/*')):\n",
    "        log_name = training_log.split('.')[0].split('_')[-1]\n",
    "        train(training_log,log_name,store_path=store_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05f7ec6",
   "metadata": {},
   "source": [
    "## Binet datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceb7f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def train_binet_logs():\n",
    "    store_path='models/binet_logs'\n",
    "    for training_log in progress_bar(glob.glob('data/csv/binet_logs/*')):\n",
    "        log_name = training_log.split('/')[-1][:-7]\n",
    "        train(training_log,log_name,store_path=store_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd8f5df",
   "metadata": {},
   "source": [
    "## Shell Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c515d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def run_training(log=\"binet\"):\n",
    "    if log == 'binet':\n",
    "        train_binet_logs()\n",
    "    elif log == 'pdc20':\n",
    "        train_pdc20_logs()\n",
    "    elif log == 'pdc21':\n",
    "        train_pdc21_logs()\n",
    "    elif log == 'all':\n",
    "        train_pdc20_logs()\n",
    "        train_pdc21_logs()\n",
    "        train_binet_logs()\n",
    "    else: \n",
    "        raise ValueError(f'{log} is not a supported data set!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c06cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dapnn",
   "language": "python",
   "name": "dapnn"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
