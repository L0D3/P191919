# AUTOGENERATED! DO NOT EDIT! File to edit: 04_training.ipynb (unless otherwise specified).

__all__ = ['train', 'train_pdc20_logs', 'train_pdc21_logs', 'train_binet_logs', 'run_training']

# Cell

from .imports import *
from .data_processing import *
from .anomaly import *


# Cell
import warnings
warnings.filterwarnings(action='once')

# Cell
import fire

# Cell
def train(fn,log_name,store_path='models',epoch=25,ws=5):
    cols= get_attr(attr_dict,fn)
    log = import_log(fn,cols)
    o,dls,categorify = training_dl(log,cols,ws=ws)
    p = f'{store_path}/{log_name}_vocab.p'
    with open(p, "wb") as output_file:
        pickle.dump(categorify, output_file)

    emb_szs = get_emb_sz(o)
    m=MultivariateModel(emb_szs)
    loss=partial(multi_loss_sum,o)
    train_val = train_validate(dls,m,loss=loss,metrics=get_metrics(o),epoch=epoch,show_plot=False,print_output=False,store_path=store_path,model_name=log_name)


# Cell
def train_pdc20_logs():
    store_path='models/pdc2020'
    for training_log in progress_bar(glob.glob('data/csv/PDC2020_training/*')):
        log_name = training_log.split('.')[0].split('_')[-1]
        train(training_log,log_name,store_path=store_path)

# Cell
def train_pdc21_logs():
    store_path='models/pdc2021'
    for training_log in progress_bar(glob.glob('data/csv/PDC2021_training/*')):
        log_name = training_log.split('.')[0].split('_')[-1]
        train(training_log,log_name,store_path=store_path)

# Cell
def train_binet_logs():
    store_path='models/binet_logs'
    for training_log in progress_bar(glob.glob('data/csv/binet_logs/*')):
        log_name = training_log.split('/')[-1][:-7]
        train(training_log,log_name,store_path=store_path)


# Cell
def run_training(log="binet"):
    if log == 'binet':
        train_binet_logs()
    elif log == 'pdc20':
        train_pdc20_logs()
    elif log == 'pdc21':
        train_pdc21_logs()
    elif log == 'all':
        train_pdc20_logs()
        train_pdc21_logs()
        train_binet_logs()
    else:
        raise ValueError(f'{log} is not a supported data set!')