# AUTOGENERATED! DO NOT EDIT! File to edit: 06_hyper_parameter.ipynb (unless otherwise specified).

__all__ = ['select_experiment_paths', 'load_pred_model', 'inference', 'hyper_param_eval']

# Cell
from .imports import *
from .data_processing import *

from .anomaly import *
import seaborn as sns
sns.set_theme(style="darkgrid")

# Cell
def select_experiment_paths(experiment,log_name):
    if experiment=='pdc20':
        pdc_year=2020
        learner_path=f'models/pdc{pdc_year}'
        training_log_path = f'data/csv/PDC{pdc_year}_training/pdc_{pdc_year}_{log_name}.csv.gz'
        test_log_path = f'data/csv/PDC{pdc_year}_ground_truth/pdc_{pdc_year}_{log_name}.csv.gz'
    elif experiment=='pdc21':
        pdc_year=2021
        learner_path=f'models/pdc{pdc_year}'
        training_log_path = f'data/csv/PDC{pdc_year}_training/pdc{pdc_year}_{log_name}.csv.gz'
        test_log_path = f'data/csv/PDC{pdc_year}_ground_truth/pdc{pdc_year}_{log_name[:-1]}.csv.gz'
    elif experiment =='binet_logs':
        learner_path=f'models/binet_logs/'
        training_log_path=f'data/csv/binet_logs/{log_name}.csv.gz'
        test_log_path=training_log_path
    else: raise ValueError(f'{experiment} is not a valid experiment key')
    return learner_path, training_log_path, test_log_path

# Cell
def load_pred_model(learner_path,train_log_path,log_name,cols=['activity']):
    log = import_log(train_log_path)
    o,dls,categorify = training_dl(log,cat_names=cols)
    loss=partial(multi_loss_sum,o)
    emb_szs = get_emb_sz(o)
    m=MultivariateModel(emb_szs)
    learn=Learner(dls, m, path=learner_path, model_dir='.', loss_func=loss, metrics=get_metrics(o))
    learn.load(log_name,with_opt=False)
    m=learn.model.cuda()
    return m, categorify

def inference(test_log_path,m,categorify,log_name,cols=['activity'],fixed_threshold=None,override_threshold_func=None):
    if type(test_log_path)==str:
        log = import_log(test_log_path)
    else:
        log = test_log_path
    o = process_test(log,categorify,cols)
    nsp,idx=predict_next_step(o,m)
    score_df=multivariate_anomaly_score(nsp,o,idx,cols)
    y_true,y_pred=multivariate_anomalies(score_df,cols,idx,o,fixed_threshold=fixed_threshold)
    if override_threshold_func is not None:
        y_true,y_pred=multivariate_anomalies(score_df,cols,idx,o,get_thresholds=override_threshold_func)
    else:
        y_true,y_pred=multivariate_anomalies(score_df,cols,idx,o,fixed_threshold=fixed_threshold)
    f1_score(y_true, y_pred)
    nsp_acc= float(nsp_accuracy(o,idx,nsp[0]))
    f1 = f1_score(y_true, y_pred)
    acc = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true,y_pred)
    recall = recall_score(y_true,y_pred)
    return [log_name, nsp_acc, f1, acc, precision, recall]

# Cell
def hyper_param_eval(epoch=1,
                     fixed_threshold=0.98,
                     num_layers = [2,3,4],
                     window_sizes = [i*2+3 for i in range(3)],
                     hidden_size = [25,50,75]):
    logs = ('pdc20','0200110'),( 'pdc21','1011100'), ('binet_logs','p2p-0.3-2'), ('binet_logs','bpic13-0.3-3')
    hyper_params = [(i,j,k) for i in num_layers for j in window_sizes  for k in hidden_size]

    res=[]
    mb = master_bar([(*select_experiment_paths(i,j),j) for i,j in logs])
    for _,training_log_path, test_log_path, log_name in mb:
        for layers,ws,neurons  in progress_bar(hyper_params,parent=mb):
            cols= get_attr(attr_dict,training_log_path)
            log = import_log(training_log_path,cols)
            o,dls,categorify = training_dl(log,cols,ws=ws)
            emb_szs = get_emb_sz(o)
            m=MultivariateModel(emb_szs,lstm_layers=layers,lstm_neurons =neurons)
            loss=partial(multi_loss_sum,o)
            train_val = train_validate(dls,m,loss=loss,metrics=get_metrics(o),epoch=epoch,show_plot=False,print_output=False)

            log = import_log(test_log_path)
            o = process_test(log,categorify,cols)
            nsp,idx=predict_next_step(o,m,ws=ws)
            score_df=multivariate_anomaly_score(nsp,o,idx,cols)
            y_true,y_pred=multivariate_anomalies(score_df,cols,idx,o,fixed_threshold=fixed_threshold,anomaly_col='anomaly' if 'binet' in training_log_path else 'normal')
            res.append([log_name,layers,neurons,ws, f1_score(y_true, y_pred)])
    columns = ['Log Name','# LSTM Layers','# LSTM hidden','Window Size','F1-Score']
    res_df=pd.DataFrame(res,columns=columns)
    res_df.to_csv('results/pred_model_hyper_params.csv')